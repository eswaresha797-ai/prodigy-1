import os
import argparse
import json
import numpy as np
from pathlib import Path
from typing import Dict, Tuple
from PIL import Image
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE
MODEL_DIR = "models"
MODEL_FILE = os.path.join(MODEL_DIR, "food_mobilenetv2.h5")
CLASS_MAP_FILE = os.path.join(MODEL_DIR, "class_map.json")
CALORIE_MAP_FILE = os.path.join(MODEL_DIR, "calorie_map.json")

DEFAULT_CALORIE_MAP = {
    "apple": 95,
    "banana": 105,
    "burger": 354,
    "pizza": 285,
    "salad": 152,
    "sushi": 200,
    "fried_rice": 242
}

def prepare_datasets(data_dir: str, img_size=IMG_SIZE, batch_size=BATCH_SIZE) -> Tuple[tf.data.Dataset, tf.data.Dataset, Dict[int, str]]:
    train_dir = Path(data_dir) / "train"
    val_dir = Path(data_dir) / "val"
    train_ds = tf.keras.preprocessing.image_dataset_from_directory(
        train_dir,
        labels="inferred",
        label_mode="int",
        image_size=img_size,
        batch_size=batch_size,
        shuffle=True
    )
    val_ds = tf.keras.preprocessing.image_dataset_from_directory(
        val_dir,
        labels="inferred",
        label_mode="int",
        image_size=img_size,
        batch_size=batch_size,
        shuffle=False
    )
    class_names = train_ds.class_names
    class_map = {i: name for i, name in enumerate(class_names)}
    def _format(ds):
        ds = ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)
        return ds.prefetch(AUTOTUNE)
    return _format(train_ds), _format(val_ds), class_map

def build_model(num_classes: int, img_size=IMG_SIZE) -> tf.keras.Model:
    base = MobileNetV2(weights="imagenet", include_top=False, input_shape=(img_size[0], img_size[1], 3))
    base.trainable = False
    inputs = tf.keras.Input(shape=(img_size[0], img_size[1], 3))
    x = base(inputs, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(num_classes, activation="softmax")(x)
    model = models.Model(inputs, outputs)
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
                  loss="sparse_categorical_crossentropy",
                  metrics=["accuracy"])
    return model

def train(data_dir: str, epochs: int = 10):
    os.makedirs(MODEL_DIR, exist_ok=True)
    train_ds, val_ds, class_map = prepare_datasets(data_dir)
    num_classes = len(class_map)
    model = build_model(num_classes)
    checkpoint = ModelCheckpoint(MODEL_FILE, monitor="val_accuracy", save_best_only=True, verbose=1)
    early = EarlyStopping(monitor="val_accuracy", patience=4, restore_best_weights=True)
    model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[checkpoint, early])
    with open(CLASS_MAP_FILE, "w") as f:
        json.dump(class_map, f)
    if not os.path.exists(CALORIE_MAP_FILE):
        with open(CALORIE_MAP_FILE, "w") as f:
            json.dump(DEFAULT_CALORIE_MAP, f)

def load_class_map() -> Dict[int, str]:
    with open(CLASS_MAP_FILE, "r") as f:
        return json.load(f)

def load_calorie_map() -> Dict[str, float]:
    if os.path.exists(CALORIE_MAP_FILE):
        with open(CALORIE_MAP_FILE, "r") as f:
            return json.load(f)
    return DEFAULT_CALORIE_MAP

def preprocess_image(img_path: str, img_size=IMG_SIZE) -> np.ndarray:
    img = Image.open(img_path).convert("RGB")
    img = img.resize(img_size)
    arr = np.array(img)
    arr = preprocess_input(arr.astype("float32"))
    arr = np.expand_dims(arr, axis=0)
    return arr

def predict(image_path: str, top_k: int = 3):
    class_map = load_class_map()
    calorie_map = load_calorie_map()
    model = tf.keras.models.load_model(MODEL_FILE)
    x = preprocess_image(image_path)
    preds = model.predict(x)[0]
    top_indices = preds.argsort()[-top_k:][::-1]
    results = []
    for idx in top_indices:
        class_name = class_map[str(idx)] if isinstance(list(class_map.keys())[0], str) else class_map[idx]
        prob = float(preds[idx])
        est_cal = calorie_map.get(class_name, None)
        results.append({"class": class_name, "probability": prob, "estimated_calories": est_cal})
    return results

def main():
    parser = argparse.ArgumentParser(description="Food recognition + calorie estimation")
    parser.add_argument("--mode", choices=["train", "predict"], required=True)
    parser.add_argument("--data_dir", type=str, default="data")
    parser.add_argument("--image", type=str)
    parser.add_argument("--epochs", type=int, default=8)
    args = parser.parse_args()
    if args.mode == "train":
        train(args.data_dir, epochs=args.epochs)
    elif args.mode == "predict":
        preds = predict(args.image, top_k=3)
        print("Top predictions:")
        for p in preds:
            print(f"  {p['class']}: {p['probability']*100:.2f}% â€” est kcal: {p['estimated_calories']}")

if _name_ == "_main_":
    main()
